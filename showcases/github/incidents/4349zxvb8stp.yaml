version: incident/v1
id: 4349zxvb8stp
name: Disruption with some GitHub services
impact: minor
systems:
    - 4230lsnqdsld
    - brv1bkgrwx7q
    - kr09ddfgbfsf
    - hhtssxt0f5v2
timeline:
    - ts: "2024-12-04 18:58:40"
      description: We are currently investigating this issue.
      investigating: true
    - ts: "2024-12-04 19:05:13"
      description: Webhooks is experiencing degraded performance. We are continuing to investigate.
      investigating: true
    - ts: "2024-12-04 19:05:31"
      description: API Requests is experiencing degraded performance. We are continuing to investigate.
      investigating: true
    - ts: "2024-12-04 19:07:56"
      description: Issues is experiencing degraded performance. We are continuing to investigate.
      investigating: true
    - ts: "2024-12-04 19:11:44"
      description: We have identified the cause of timeouts impacting users across multiple services. This change was rolled back and we are seeing recovery. We will continue to monitor for complete recovery.
      investigating: true
    - ts: "2024-12-04 19:17:24"
      description: Webhooks is operating normally.
      investigating: true
    - ts: "2024-12-04 19:18:19"
      description: API Requests is operating normally.
      investigating: true
    - ts: "2024-12-04 19:20:23"
      description: Issues is operating normally.
      investigating: true
    - ts: "2024-12-04 19:21:22"
      description: Pull Requests is experiencing degraded performance. We are continuing to investigate.
      investigating: true
    - ts: "2024-12-04 19:26:22"
      description: Pull Requests is operating normally.
      investigating: true
    - ts: "2024-12-04 19:27:34"
      description: On December 4th, 2024 between 18:52 UTC and 19:11 UTC, several GitHub services were degraded with an average error rate of 8%.<br /><br />The incident was caused by a change to a centralized authorization service that contained an unoptimized database query. This led to an increase in overall load on a shared database cluster, resulting in a cascading effect on multiple services and specifically affecting repository access authorization checks. We mitigated the incident after rolling back the change at 19:07 UTC, fully recovering within 4 minutes. <br /><br />While this incident was caught and remedied quickly, we are implementing process improvements around recognizing and reducing risk of changes involving high volume authorization checks. We are investing in broad improvements to our safe rollout process, such as improving early detection mechanisms.
      resolved: true
