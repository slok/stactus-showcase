version: incident/v1
id: c7kq3ctclddp
name: Incident with Actions
impact: minor
systems:
    - br0l2tvcx85d
timeline:
    - ts: "2025-08-21 15:54:34"
      description: We are investigating reports of degraded performance for Actions
      investigating: true
    - ts: "2025-08-21 16:05:31"
      description: We are investigating reports of slow queue times for Hosted Runners, leading to high wait times.
      investigating: true
    - ts: "2025-08-21 16:43:49"
      description: The team continues to investigate issues with some Actions jobs on Hosted Runners being queued for a long time and a percentage of jobs failing. We will continue providing updates on the progress towards mitigation.
      investigating: true
    - ts: "2025-08-21 17:21:37"
      description: The team continues to investigate issues with some Actions jobs on Hosted Runners being queued for a long time and a percentage of jobs failing. We are increasing runner capacity and will continue providing updates on the progress towards mitigation.
      investigating: true
    - ts: "2025-08-21 17:58:04"
      description: We've applied a mitigation to fix the issues with queuing and running Actions jobs. We are seeing improvements in telemetry and are monitoring for full recovery.
      investigating: true
    - ts: "2025-08-21 18:13:02"
      description: On August 21, 2025, from approximately 15:37 UTC to 18:10 UTC, customers experienced increased delays and failures when starting jobs on GitHub Actions using standard hosted runners. This was caused by connectivity issues in our East US region, which prevented runners from retrieving jobs and sending progress updates. As a result, capacity was significantly reduced, especially for busier configurations, leading to queuing and service interruptions. Approximately 8.05% of jobs on public standard Ubuntu24 runners and 3.4% of jobs on private standard Ubuntu24 runners did not start as expected.<br /><br />By 18:10 UTC, we had mitigated the issue by provisioning additional resources in the affected region and burning down the backlog of queued runner assignments. By the end of that day, we deployed changes to improve runner connectivity resilience and graceful degradation in similar situations.  We are also taking further steps to improve system resiliency by enhancing observability of network connection health with runners and improving load distribution and failover handling to help prevent similar issues in the future.
      resolved: true
